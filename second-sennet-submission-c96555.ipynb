{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32a6cbf5",
   "metadata": {
    "papermill": {
     "duration": 0.008241,
     "end_time": "2023-12-09T04:21:25.070881",
     "exception": false,
     "start_time": "2023-12-09T04:21:25.062640",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a02fc38",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-output": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-12-09T04:21:25.087458Z",
     "iopub.status.busy": "2023-12-09T04:21:25.086990Z",
     "iopub.status.idle": "2023-12-09T04:21:44.899355Z",
     "shell.execute_reply": "2023-12-09T04:21:44.898361Z"
    },
    "papermill": {
     "duration": 19.823069,
     "end_time": "2023-12-09T04:21:44.901711",
     "exception": false,
     "start_time": "2023-12-09T04:21:25.078642",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: /kaggle/input/pip-download-for-segmentation-models-pytorch\r\n",
      "Processing /kaggle/input/pip-download-for-segmentation-models-pytorch/segmentation_models_pytorch-0.3.3-py3-none-any.whl\r\n",
      "Requirement already satisfied: torchvision>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from segmentation-models-pytorch) (0.15.1)\r\n",
      "Processing /kaggle/input/pip-download-for-segmentation-models-pytorch/pretrainedmodels-0.7.4.tar.gz (from segmentation-models-pytorch)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25hProcessing /kaggle/input/pip-download-for-segmentation-models-pytorch/efficientnet_pytorch-0.7.1.tar.gz (from segmentation-models-pytorch)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hProcessing /kaggle/input/pip-download-for-segmentation-models-pytorch/timm-0.9.2-py3-none-any.whl (from segmentation-models-pytorch)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from segmentation-models-pytorch) (4.66.1)\r\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (from segmentation-models-pytorch) (10.1.0)\r\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2.0.0)\r\n",
      "Processing /kaggle/input/pip-download-for-segmentation-models-pytorch/munch-4.0.0-py2.py3-none-any.whl (from pretrainedmodels==0.7.4->segmentation-models-pytorch)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from timm==0.9.2->segmentation-models-pytorch) (6.0.1)\r\n",
      "Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from timm==0.9.2->segmentation-models-pytorch) (0.19.4)\r\n",
      "Requirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from timm==0.9.2->segmentation-models-pytorch) (0.4.1)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (1.24.3)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (2.31.0)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.12.2)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (4.5.0)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (1.12)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.1.2)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->timm==0.9.2->segmentation-models-pytorch) (2023.12.1)\r\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->timm==0.9.2->segmentation-models-pytorch) (21.3)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (3.2.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (1.26.15)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (2023.11.17)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub->timm==0.9.2->segmentation-models-pytorch) (3.0.9)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2.1.3)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (1.3.0)\r\n",
      "Building wheels for collected packages: efficientnet-pytorch, pretrainedmodels\r\n",
      "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16428 sha256=44009aa1458b5c10e4595843fadd163fa2d3ee46c9b6cd608a0d696529f6b1f6\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/d2/e7/71/a031831a75a14914d29e2f255fcbc113d825ff4762d42f0315\r\n",
      "  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25h  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60943 sha256=c87f21498330950bfb8d136f2ecd63463d5d75c785fed5df9c21ca3404507e7b\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/10/53/cc/d9cbdaa15d821ad4845e69994708dcad78fcddf4c92a753bdf\r\n",
      "Successfully built efficientnet-pytorch pretrainedmodels\r\n",
      "Installing collected packages: munch, efficientnet-pytorch, timm, pretrainedmodels, segmentation-models-pytorch\r\n",
      "  Attempting uninstall: timm\r\n",
      "    Found existing installation: timm 0.9.12\r\n",
      "    Uninstalling timm-0.9.12:\r\n",
      "      Successfully uninstalled timm-0.9.12\r\n",
      "Successfully installed efficientnet-pytorch-0.7.1 munch-4.0.0 pretrainedmodels-0.7.4 segmentation-models-pytorch-0.3.3 timm-0.9.2\r\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install --no-index --find-links=/kaggle/input/pip-download-for-segmentation-models-pytorch segmentation-models-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac3ba0a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-09T04:21:44.922685Z",
     "iopub.status.busy": "2023-12-09T04:21:44.922346Z",
     "iopub.status.idle": "2023-12-09T04:21:54.398809Z",
     "shell.execute_reply": "2023-12-09T04:21:54.398034Z"
    },
    "papermill": {
     "duration": 9.48963,
     "end_time": "2023-12-09T04:21:54.401294",
     "exception": false,
     "start_time": "2023-12-09T04:21:44.911664",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import gc\n",
    "import time\n",
    "from collections import defaultdict\n",
    "import  matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "import copy\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.cuda import amp\n",
    "import torch.optim as optim\n",
    "import albumentations as A\n",
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "734dd857",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-09T04:21:54.421708Z",
     "iopub.status.busy": "2023-12-09T04:21:54.421399Z",
     "iopub.status.idle": "2023-12-09T04:21:54.427665Z",
     "shell.execute_reply": "2023-12-09T04:21:54.426750Z"
    },
    "papermill": {
     "duration": 0.018727,
     "end_time": "2023-12-09T04:21:54.429702",
     "exception": false,
     "start_time": "2023-12-09T04:21:54.410975",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_img(path):\n",
    "    img = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n",
    "    img = np.tile(img[...,None], [1, 1, 3]) # gray to rgb\n",
    "    img = img.astype('float32') # original is uint16\n",
    "    mx = np.max(img)\n",
    "    if mx:\n",
    "        img/=mx # scale image to [0, 1]\n",
    "    return img\n",
    "\n",
    "def load_msk(path):\n",
    "    msk = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n",
    "    msk = msk.astype('float32')\n",
    "    msk/=255.0\n",
    "    return msk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc10553b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-09T04:21:54.449891Z",
     "iopub.status.busy": "2023-12-09T04:21:54.449550Z",
     "iopub.status.idle": "2023-12-09T04:21:54.458997Z",
     "shell.execute_reply": "2023-12-09T04:21:54.458292Z"
    },
    "papermill": {
     "duration": 0.021689,
     "end_time": "2023-12-09T04:21:54.460967",
     "exception": false,
     "start_time": "2023-12-09T04:21:54.439278",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BuildDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, img_paths, msk_paths=[], transforms=None):\n",
    "        self.img_paths  = img_paths\n",
    "        self.msk_paths  = msk_paths\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img_path  = self.img_paths[index]\n",
    "        img = load_img(img_path)\n",
    "        \n",
    "        if len(self.msk_paths)>0:\n",
    "            msk_path = self.msk_paths[index]\n",
    "            msk = load_msk(msk_path)\n",
    "            if self.transforms:\n",
    "                data = self.transforms(image=img, mask=msk)\n",
    "                img  = data['image']\n",
    "                msk  = data['mask']\n",
    "            img = np.transpose(img, (2, 0, 1))\n",
    "            return torch.tensor(img), torch.tensor(msk)\n",
    "        else:\n",
    "            orig_size = img.shape\n",
    "            if self.transforms:\n",
    "                data = self.transforms(image=img)\n",
    "                img  = data['image']\n",
    "            img = np.transpose(img, (2, 0, 1))\n",
    "            return torch.tensor(img), torch.tensor(np.array([orig_size[0], orig_size[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05ae8c8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-09T04:21:54.480676Z",
     "iopub.status.busy": "2023-12-09T04:21:54.480351Z",
     "iopub.status.idle": "2023-12-09T04:21:54.775241Z",
     "shell.execute_reply": "2023-12-09T04:21:54.774429Z"
    },
    "papermill": {
     "duration": 0.307241,
     "end_time": "2023-12-09T04:21:54.777639",
     "exception": false,
     "start_time": "2023-12-09T04:21:54.470398",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found images: 6\n"
     ]
    }
   ],
   "source": [
    "DATASET_FOLDER = \"/kaggle/input/blood-vessel-segmentation\"\n",
    "ls_images = glob(os.path.join(DATASET_FOLDER, \"test\", \"*\", \"images\", \"*.tif\"))\n",
    "print(f\"found images: {len(ls_images)}\")\n",
    "\n",
    "# ===============================================================================\n",
    "# /kaggle/input/blood-vessel-segmentation/train/kidney_1_dense\n",
    "# /kaggle/input/blood-vessel-segmentation/train/kidney_2\n",
    "# sanity check\n",
    "base_path = '/kaggle/input/blood-vessel-segmentation/train'  \n",
    "train_base_path = '/kaggle/input/patched-sennet-kidney-1-data'\n",
    "val_img = \"kidney_2\"#'kidney_3_sparse',kidney_1_dense\n",
    "val_mask = \"kidney_2\"#'kidney_3_sparse',kidney_1_dense\n",
    "\n",
    "images_val_path = os.path.join(base_path, val_img, 'images')\n",
    "labels_val_path = os.path.join(base_path, val_mask, 'labels')\n",
    "image_val_files = sorted([os.path.join(images_val_path, f) for f in os.listdir(images_val_path) if f.endswith('.tif')])\n",
    "label_val_files = sorted([os.path.join(labels_val_path, f) for f in os.listdir(labels_val_path) if f.endswith('.tif')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f70addcb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-09T04:21:54.798938Z",
     "iopub.status.busy": "2023-12-09T04:21:54.798176Z",
     "iopub.status.idle": "2023-12-09T04:21:54.803878Z",
     "shell.execute_reply": "2023-12-09T04:21:54.803012Z"
    },
    "papermill": {
     "duration": 0.018361,
     "end_time": "2023-12-09T04:21:54.805896",
     "exception": false,
     "start_time": "2023-12-09T04:21:54.787535",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dataset = BuildDataset(ls_images, [], transforms=None)\n",
    "sanity_dataset = BuildDataset(image_val_files,label_val_files,transforms=None )\n",
    "sanity_loader = DataLoader(sanity_dataset, batch_size = 1, num_workers=0, shuffle=False, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size = 1, num_workers=0, shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e184e47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-09T04:21:54.826621Z",
     "iopub.status.busy": "2023-12-09T04:21:54.826342Z",
     "iopub.status.idle": "2023-12-09T04:21:54.930202Z",
     "shell.execute_reply": "2023-12-09T04:21:54.929158Z"
    },
    "papermill": {
     "duration": 0.11585,
     "end_time": "2023-12-09T04:21:54.932168",
     "exception": false,
     "start_time": "2023-12-09T04:21:54.816318",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# resnext50_32x4d\n",
    "# resnet50\n",
    "\n",
    "#/kaggle/input/resnext-800/best_epoch800.bin\n",
    "#/kaggle/input/renext-patch-50d/renext_patch.bin\n",
    "class CFG:\n",
    "    backbone = \"resnext50_32x4d\"\n",
    "    bin_path = '/kaggle/input/unet-attetion-patch/best_epoch (11).bin'\n",
    "    test_batchsize = 1\n",
    "    img_size = [800,800]\n",
    "    remove_area = 30\n",
    "    threshold = 0.9\n",
    "    over_lap = 0.1\n",
    "    num_classes   = 1\n",
    "    patch_size = 800\n",
    "    device        = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#     data_transforms = {\n",
    "#         \"train\": A.Compose([\n",
    "#             A.Resize(*img_size, interpolation=cv2.INTER_NEAREST),\n",
    "#             A.HorizontalFlip(p=0.5),\n",
    "#             A.VerticalFlip(p=0.5),\n",
    "#         ], p=1.0),\n",
    "        \n",
    "#         \"valid\": A.Compose([\n",
    "#             A.Resize(*img_size, interpolation=cv2.INTER_NEAREST),\n",
    "#         ], p=1.0)\n",
    "#     }\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfeb589",
   "metadata": {
    "papermill": {
     "duration": 0.010007,
     "end_time": "2023-12-09T04:21:54.951581",
     "exception": false,
     "start_time": "2023-12-09T04:21:54.941574",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# for new way remember to make batch_size to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cec3e935",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-09T04:21:54.971180Z",
     "iopub.status.busy": "2023-12-09T04:21:54.970829Z",
     "iopub.status.idle": "2023-12-09T04:21:54.998502Z",
     "shell.execute_reply": "2023-12-09T04:21:54.997683Z"
    },
    "papermill": {
     "duration": 0.039943,
     "end_time": "2023-12-09T04:21:55.000422",
     "exception": false,
     "start_time": "2023-12-09T04:21:54.960479",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class attention_block(nn.Module):\n",
    "    def __init__(self, F_g, F_l, n_coefficients):\n",
    "        super(attention_block, self).__init__()\n",
    "\n",
    "        self.bypass = nn.Sequential(\n",
    "            nn.Conv2d(F_g, n_coefficients, kernel_size=1, stride=1, padding=0, bias=True),\n",
    "            nn.BatchNorm2d(n_coefficients)\n",
    "        )\n",
    "\n",
    "        self.upsample = nn.Sequential(\n",
    "            nn.Conv2d(F_l, n_coefficients, kernel_size=1, stride=1, padding=0, bias=True),\n",
    "            nn.BatchNorm2d(n_coefficients)\n",
    "        )\n",
    "\n",
    "        self.psi = nn.Sequential(\n",
    "            nn.Conv2d(n_coefficients, 1, kernel_size=1, stride=1, padding=0, bias=True),\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, gate, skip_connection):\n",
    "        \"\"\"\n",
    "        :param gate: gating signal from previous layer\n",
    "        :param skip_connection: activation from corresponding encoder layer\n",
    "        :return: output activations\n",
    "        \"\"\"\n",
    "        g1 = self.upsample(gate)\n",
    "        x1 = self.bypass(skip_connection)\n",
    "        psi = self.relu(g1 + x1)\n",
    "        psi = self.psi(psi)\n",
    "        out = skip_connection * psi\n",
    "        return out\n",
    "\n",
    "class MyUNet(nn.Module):\n",
    "    def contracting_block(self, in_channels, out_channels, kernel_size=3):\n",
    "        block = torch.nn.Sequential(\n",
    "                    torch.nn.Conv2d(kernel_size=kernel_size, in_channels=in_channels, out_channels=out_channels, padding=1),\n",
    "                    torch.nn.ReLU(),\n",
    "                    torch.nn.BatchNorm2d(out_channels),\n",
    "                    torch.nn.Conv2d(kernel_size=kernel_size, in_channels=out_channels, out_channels=out_channels, padding=1),\n",
    "                    torch.nn.ReLU(),\n",
    "                )\n",
    "        return block\n",
    "    def expansive_block(self, in_channels, mid_channel, out_channels, kernel_size=3):\n",
    "            block = torch.nn.Sequential(\n",
    "                    torch.nn.Conv2d(kernel_size=kernel_size, in_channels=in_channels, out_channels=mid_channel, padding=1),\n",
    "                    torch.nn.ReLU(),\n",
    "                    torch.nn.BatchNorm2d(mid_channel),\n",
    "                    torch.nn.Conv2d(kernel_size=kernel_size, in_channels=mid_channel, out_channels=mid_channel, padding=1),\n",
    "                    torch.nn.ReLU(),\n",
    "                    torch.nn.BatchNorm2d(mid_channel),\n",
    "                    torch.nn.ConvTranspose2d(in_channels=mid_channel, out_channels=out_channels, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "            )\n",
    "            return  block\n",
    "\n",
    "    def final_block(self, in_channels, mid_channel, out_channels, kernel_size=1):\n",
    "            block = torch.nn.Sequential(\n",
    "                    \n",
    "                    torch.nn.Conv2d(kernel_size=3, in_channels=in_channels, out_channels=mid_channel, padding=1),\n",
    "                    torch.nn.ReLU(),\n",
    "                    torch.nn.BatchNorm2d(mid_channel),\n",
    "                    torch.nn.Conv2d(kernel_size=kernel_size, in_channels=mid_channel, out_channels=out_channels, padding=0),\n",
    "                    torch.nn.ReLU(),\n",
    "                    torch.nn.BatchNorm2d(out_channels),\n",
    "            )\n",
    "            return  block\n",
    "\n",
    "    def __init__(self, in_channel, out_channel):\n",
    "        super(MyUNet, self).__init__()\n",
    "        #Encode\n",
    "        self.conv_encode1 = self.contracting_block(in_channels=in_channel, out_channels=64)\n",
    "        self.conv_maxpool1 = torch.nn.MaxPool2d(kernel_size=2)\n",
    "        self.conv_encode2 = self.contracting_block(64, 128)\n",
    "        self.conv_maxpool2 = torch.nn.MaxPool2d(kernel_size=2)\n",
    "        self.conv_encode3 = self.contracting_block(128, 256)\n",
    "        self.conv_maxpool3 = torch.nn.MaxPool2d(kernel_size=2)\n",
    "        # Bottleneck\n",
    "        self.bottleneck = torch.nn.Sequential(\n",
    "                            torch.nn.Conv2d(kernel_size=3, in_channels=256, out_channels=512, padding=1),\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.BatchNorm2d(512),\n",
    "                            torch.nn.Conv2d(kernel_size=3, in_channels=512, out_channels=512, padding=1),\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.BatchNorm2d(512),\n",
    "                            torch.nn.ConvTranspose2d(in_channels=512, out_channels=256, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "                            )\n",
    "\n",
    "        # Decode\n",
    "        self.attention3 = attention_block(256, 256, 128)\n",
    "        self.conv_decode3 = self.expansive_block(512, 256, 128)\n",
    "        self.attention2 = attention_block(128, 128, 64)\n",
    "        self.conv_decode2 = self.expansive_block(256, 128, 64)\n",
    "        self.attention1 = attention_block(64, 64, 32)\n",
    "        self.final_layer = self.final_block(128, 64, out_channel)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Encode\n",
    "        encode_block1 = self.conv_encode1(x)\n",
    "        encode_pool1 = self.conv_maxpool1(encode_block1)\n",
    "        encode_block2 = self.conv_encode2(encode_pool1)\n",
    "        encode_pool2 = self.conv_maxpool2(encode_block2)\n",
    "        encode_block3 = self.conv_encode3(encode_pool2)\n",
    "        encode_pool3 = self.conv_maxpool3(encode_block3)\n",
    "        # Bottleneck\n",
    "        bottle_neck1 = self.bottleneck(encode_pool3)\n",
    "        # Decode\n",
    "        att_3 = self.attention3(bottle_neck1, encode_block3) \n",
    "        decode_block1 = torch.cat((bottle_neck1, att_3), 1)\n",
    "        cat_layer2 = self.conv_decode3(decode_block1)\n",
    "        \n",
    "        att_2 = self.attention2(cat_layer2, encode_block2) \n",
    "        decode_block2 = torch.cat((cat_layer2, att_2), 1)\n",
    "        cat_layer1 = self.conv_decode2(decode_block2)\n",
    "        \n",
    "        \n",
    "        att_1 = self.attention1(cat_layer1, encode_block1) \n",
    "        decode_block3 = torch.cat((cat_layer1, att_1), 1)\n",
    "        final_layer = self.final_layer(decode_block3)\n",
    "        return final_layer\n",
    "def build_model(backbone, num_classes, device):\n",
    "    model = MyUNet(in_channel=3, out_channel=num_classes)\n",
    "    model.to(device)\n",
    "    return model\n",
    "\n",
    "def load_model(backbone, num_classes, device, path):\n",
    "    model = build_model(backbone, num_classes, device)\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6ab3cf3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-09T04:21:55.020370Z",
     "iopub.status.busy": "2023-12-09T04:21:55.020013Z",
     "iopub.status.idle": "2023-12-09T04:21:58.318166Z",
     "shell.execute_reply": "2023-12-09T04:21:58.316875Z"
    },
    "papermill": {
     "duration": 3.311497,
     "end_time": "2023-12-09T04:21:58.321472",
     "exception": false,
     "start_time": "2023-12-09T04:21:55.009975",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = load_model(CFG.backbone, \n",
    "                   1, \n",
    "                   CFG.device, \n",
    "                   CFG.bin_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a415156c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-09T04:21:58.356978Z",
     "iopub.status.busy": "2023-12-09T04:21:58.355599Z",
     "iopub.status.idle": "2023-12-09T04:21:58.364956Z",
     "shell.execute_reply": "2023-12-09T04:21:58.363996Z"
    },
    "papermill": {
     "duration": 0.030237,
     "end_time": "2023-12-09T04:21:58.367546",
     "exception": false,
     "start_time": "2023-12-09T04:21:58.337309",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rle_encode(img):\n",
    "    '''\n",
    "    img: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    pixels = img.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    rle = ' '.join(str(x) for x in runs)\n",
    "    if rle == '':\n",
    "        rle = '1 0'\n",
    "    return rle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d272d94e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-09T04:21:58.393943Z",
     "iopub.status.busy": "2023-12-09T04:21:58.393387Z",
     "iopub.status.idle": "2023-12-09T04:21:58.399965Z",
     "shell.execute_reply": "2023-12-09T04:21:58.399118Z"
    },
    "papermill": {
     "duration": 0.022502,
     "end_time": "2023-12-09T04:21:58.402646",
     "exception": false,
     "start_time": "2023-12-09T04:21:58.380144",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def remove_small_objects(img, min_size):\n",
    "    # Find all connected components (labels)\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(img, connectivity=8)\n",
    "\n",
    "    # Create a mask where small objects are removed\n",
    "    new_img = np.zeros_like(img)\n",
    "    for label in range(1, num_labels):\n",
    "        if stats[label, cv2.CC_STAT_AREA] >= min_size:\n",
    "            new_img[labels == label] = 255\n",
    "\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e95c808",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-09T04:21:58.427989Z",
     "iopub.status.busy": "2023-12-09T04:21:58.427390Z",
     "iopub.status.idle": "2023-12-09T04:21:58.441752Z",
     "shell.execute_reply": "2023-12-09T04:21:58.441007Z"
    },
    "papermill": {
     "duration": 0.027051,
     "end_time": "2023-12-09T04:21:58.443609",
     "exception": false,
     "start_time": "2023-12-09T04:21:58.416558",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def patch_image(img, patch_size, model = None, over_lap=0.2):\n",
    "    \"\"\"\n",
    "    Splits the image into patches with overlap.\n",
    "\n",
    "    \"\"\"\n",
    "    shape = img.shape\n",
    "\n",
    "    height, width = shape[2],shape[3]\n",
    "\n",
    "    stride = patch_size * (1 - over_lap)\n",
    "    num_patches = np.ceil(np.array([height, width]) / stride).astype(np.int64)\n",
    "    \n",
    "    starts = [np.int64(np.linspace(0, width - patch_size, num_patches[1])),\n",
    "              np.int64(np.linspace(0, height - patch_size, num_patches[0]))]\n",
    "    patches = []\n",
    "    for y in starts[1]:\n",
    "        for x in starts[0]:\n",
    "            if model != None: \n",
    "                patch_img = img[:,:,y:y + patch_size, x:x + patch_size]\n",
    "#                 print(type(patch_img),\" and shape is \",patch_img.shape)\n",
    "#                 print(f'inside the patch function: size of patched image: {np.shape(patch_img)}')\n",
    "                patches.append(patch_img)\n",
    "    patches = torch.cat(patches,dim = 0)\n",
    "    pred = model(patches)\n",
    "    return pred\n",
    "\n",
    "\n",
    "def combine_patches_torch(patches, original_shape, patch_size, over_lap=0.1):\n",
    "    height, width = original_shape[2],original_shape[3]\n",
    "    stride = int(patch_size * (1 - over_lap))\n",
    "    combined = np.zeros((height, width), dtype=np.float32)\n",
    "    weight = np.zeros((height, width), dtype=np.float32)\n",
    "\n",
    "    num_patches_y = np.ceil(height / stride).astype(np.int64)\n",
    "    num_patches_x = np.ceil(width / stride).astype(np.int64)\n",
    "\n",
    "    starts_y = np.linspace(0, height - patch_size, num_patches_y).astype(np.int64)\n",
    "    starts_x = np.linspace(0, width - patch_size, num_patches_x).astype(np.int64)\n",
    "\n",
    "    patch_idx = 0\n",
    "    for y in starts_y:\n",
    "        for x in starts_x:\n",
    "            \n",
    "            patch = patches[patch_idx].detach().cpu()\n",
    "            patch = patch.numpy().astype(np.float32)\n",
    "#             print(f'inside the combine function: type of combine = {type(combined)}, shape of patches = {np.shape(patch)}')\n",
    "            # with torch, I cannot add different sized tensor together \n",
    "            combined[y:y + patch_size, x:x + patch_size] += patch.squeeze()\n",
    "            weight[y:y + patch_size, x:x + patch_size] += 1.0\n",
    "            patch_idx += 1\n",
    "\n",
    "    # Avoid division by zero\n",
    "    weight[weight == 0] = 1.0\n",
    "    combined = combined / weight\n",
    "    combined = torch.from_numpy(combined)\n",
    "    combined = combined.unsqueeze(0).unsqueeze(0)\n",
    "    \n",
    "    return combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351a2b59",
   "metadata": {
    "papermill": {
     "duration": 0.008816,
     "end_time": "2023-12-09T04:21:58.462165",
     "exception": false,
     "start_time": "2023-12-09T04:21:58.453349",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# inference for resize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca21331f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-09T04:21:58.482703Z",
     "iopub.status.busy": "2023-12-09T04:21:58.481912Z",
     "iopub.status.idle": "2023-12-09T04:21:58.486412Z",
     "shell.execute_reply": "2023-12-09T04:21:58.485612Z"
    },
    "papermill": {
     "duration": 0.0168,
     "end_time": "2023-12-09T04:21:58.488362",
     "exception": false,
     "start_time": "2023-12-09T04:21:58.471562",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# rles = []\n",
    "# pbar = tqdm(enumerate(test_loader), total=len(test_loader), desc='Inference ')\n",
    "# for step, (images, shapes) in pbar:\n",
    "# #     print(np.shape(images))\n",
    "#     shapes = shapes.numpy()\n",
    "#     images = images.to(device, dtype=torch.float)\n",
    "#     with torch.no_grad():\n",
    "#         preds = model(images)\n",
    "#         print(f'shape of raw prediction {np.shape(preds)}')\n",
    "# #         preds = (nn.Sigmoid()(preds)>0.5).double()\n",
    "#         preds = (preds>CFG.threshold).float()\n",
    "#         print(f'shape of prediction after sigmoid {np.shape(preds)}')\n",
    "#     preds = preds.cpu().numpy().astype(np.uint8)\n",
    "\n",
    "#     for pred, shape in zip(preds, shapes):\n",
    "#         pred = cv2.resize(pred[0], (shape[1], shape[0]), cv2.INTER_NEAREST)\n",
    "#         rle = rle_encode_submission(remove_small_objects(pred,30))\n",
    "#         rles.append(rle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6502f7",
   "metadata": {
    "papermill": {
     "duration": 0.008986,
     "end_time": "2023-12-09T04:21:58.506851",
     "exception": false,
     "start_time": "2023-12-09T04:21:58.497865",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Inference for patch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5cc20312",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-09T04:21:58.526995Z",
     "iopub.status.busy": "2023-12-09T04:21:58.526430Z",
     "iopub.status.idle": "2023-12-09T04:22:08.043630Z",
     "shell.execute_reply": "2023-12-09T04:22:08.042549Z"
    },
    "papermill": {
     "duration": 9.529436,
     "end_time": "2023-12-09T04:22:08.045771",
     "exception": false,
     "start_time": "2023-12-09T04:21:58.516335",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference : 100%|██████████| 6/6 [00:09<00:00,  1.58s/it]\n"
     ]
    }
   ],
   "source": [
    "rles = []\n",
    "pbar = tqdm(enumerate(test_loader), total=len(test_loader), desc='Inference ')\n",
    "for step, (images, shapes) in pbar:\n",
    "#     print(np.shape(images))\n",
    "    shapes = shapes.numpy()\n",
    "    images = images.to(device, dtype=torch.float)\n",
    "    with torch.no_grad():\n",
    "        ori_shape = images.shape\n",
    "#         print(ori_shape)\n",
    "#         print(np.shape(images))\n",
    "        patches = patch_image(images,patch_size = CFG.patch_size,model = model,over_lap = CFG.over_lap)\n",
    "        pred  = combine_patches_torch(patches,ori_shape,patch_size = CFG.patch_size,over_lap = CFG.over_lap )\n",
    "        pred = pred.cpu().numpy()\n",
    "        pred = ((pred>CFG.threshold)*255).astype(np.uint8)\n",
    "    pred = pred.squeeze()\n",
    "#     print(f'shape of raw prediction {np.shape(pred)}')\n",
    "    rle = rle_encode(remove_small_objects(pred,CFG.remove_area))\n",
    "    rles.append(rle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37e557e",
   "metadata": {
    "papermill": {
     "duration": 0.010134,
     "end_time": "2023-12-09T04:22:08.066616",
     "exception": false,
     "start_time": "2023-12-09T04:22:08.056482",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc15b9be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-09T04:22:08.088607Z",
     "iopub.status.busy": "2023-12-09T04:22:08.087874Z",
     "iopub.status.idle": "2023-12-09T04:22:08.093979Z",
     "shell.execute_reply": "2023-12-09T04:22:08.093069Z"
    },
    "papermill": {
     "duration": 0.019507,
     "end_time": "2023-12-09T04:22:08.095914",
     "exception": false,
     "start_time": "2023-12-09T04:22:08.076407",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sample_ids = [random.randint(0, len(sanity_dataset)) for _ in range(20)]\n",
    "# for id in sample_ids:\n",
    "#     images, mask = sanity_dataset[id]\n",
    "#     images = images.to(device, dtype=torch.float)\n",
    "#     with torch.no_grad():\n",
    "        \n",
    "#         image = images.unsqueeze(0)\n",
    "#         ori_shape = image.shape\n",
    "#         patches = patch_image(image,patch_size = CFG.patch_size,model = model,over_lap = CFG.over_lap)\n",
    "#         pred  = combine_patches_torch(patches,ori_shape,patch_size = CFG.patch_size,over_lap = CFG.over_lap )\n",
    "#         pred = (nn.Sigmoid()(pred)>.5).float()\n",
    "#         pred = pred.cpu().numpy().astype(np.uint8)\n",
    "#         plt.figure(figsize=(9, 4))\n",
    "#         plt.subplot(1,3,1)\n",
    "#         image = image.cpu().detach().numpy()\n",
    "#         image = image.squeeze(0)\n",
    "#         image = np.transpose(image,(1,2,0))\n",
    "#         plt.imshow(image)\n",
    "#         plt.subplot(1,3,2)\n",
    "#         plt.imshow(mask)\n",
    "#         plt.subplot(1,3,3)\n",
    "#         pred = pred.squeeze()\n",
    "#         plt.imshow(pred)\n",
    "#         plt.show()\n",
    "    \n",
    "\n",
    "# for images, shapes in test_loader:\n",
    "# #     print(np.shape(images))\n",
    "#     shapes = shapes.numpy()\n",
    "#     images = images.to(device, dtype=torch.float)\n",
    "#     with torch.no_grad():\n",
    "#         ori_shape = images.shape\n",
    "# #         print(ori_shape)\n",
    "#         image = images[0]\n",
    "#         patches = patch_image(images,512,model = model)\n",
    "#         pred  = combine_patches_torch(patches,ori_shape,512)\n",
    "#         pred = (nn.Sigmoid()(pred)>.9).float()\n",
    "#         pred = pred.cpu().numpy().astype(np.uint8)\n",
    "#         plt.figure(figsize=(9, 4))\n",
    "#         plt.subplot(1,2,1)\n",
    "#         image = image.cpu().detach().numpy()\n",
    "#         image = np.transpose(image,(1,2,0))\n",
    "#         plt.imshow(image)\n",
    "#         plt.subplot(1,2,2)\n",
    "#         pred = pred.squeeze()\n",
    "#         plt.imshow(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d1674c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-09T04:22:08.118106Z",
     "iopub.status.busy": "2023-12-09T04:22:08.117231Z",
     "iopub.status.idle": "2023-12-09T04:22:08.125558Z",
     "shell.execute_reply": "2023-12-09T04:22:08.124670Z"
    },
    "papermill": {
     "duration": 0.021316,
     "end_time": "2023-12-09T04:22:08.127634",
     "exception": false,
     "start_time": "2023-12-09T04:22:08.106318",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 39631.22it/s]\n"
     ]
    }
   ],
   "source": [
    "ids = []\n",
    "for p_img in tqdm(ls_images):\n",
    "    path_ = p_img.split(os.path.sep)\n",
    "    # parse the submission ID\n",
    "    dataset = path_[-3]\n",
    "    slice_id, _ = os.path.splitext(path_[-1])\n",
    "    ids.append(f\"{dataset}_{slice_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "73e80e2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-09T04:22:08.149622Z",
     "iopub.status.busy": "2023-12-09T04:22:08.149271Z",
     "iopub.status.idle": "2023-12-09T04:22:08.161029Z",
     "shell.execute_reply": "2023-12-09T04:22:08.159985Z"
    },
    "papermill": {
     "duration": 0.025041,
     "end_time": "2023-12-09T04:22:08.163073",
     "exception": false,
     "start_time": "2023-12-09T04:22:08.138032",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame.from_dict({\n",
    "    \"id\": ids,\n",
    "    \"rle\": rles\n",
    "})\n",
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "58221e50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-09T04:22:08.185848Z",
     "iopub.status.busy": "2023-12-09T04:22:08.185540Z",
     "iopub.status.idle": "2023-12-09T04:22:08.201566Z",
     "shell.execute_reply": "2023-12-09T04:22:08.200505Z"
    },
    "papermill": {
     "duration": 0.030563,
     "end_time": "2023-12-09T04:22:08.204355",
     "exception": false,
     "start_time": "2023-12-09T04:22:08.173792",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>rle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kidney_5_0001</td>\n",
       "      <td>1 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kidney_5_0002</td>\n",
       "      <td>1 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kidney_5_0000</td>\n",
       "      <td>1 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kidney_6_0001</td>\n",
       "      <td>1 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kidney_6_0002</td>\n",
       "      <td>1 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>kidney_6_0000</td>\n",
       "      <td>1 0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  rle\n",
       "0  kidney_5_0001  1 0\n",
       "1  kidney_5_0002  1 0\n",
       "2  kidney_5_0000  1 0\n",
       "3  kidney_6_0001  1 0\n",
       "4  kidney_6_0002  1 0\n",
       "5  kidney_6_0000  1 0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e726df",
   "metadata": {
    "papermill": {
     "duration": 0.010732,
     "end_time": "2023-12-09T04:22:08.229855",
     "exception": false,
     "start_time": "2023-12-09T04:22:08.219123",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 6962461,
     "sourceId": 61446,
     "sourceType": "competition"
    },
    {
     "datasetId": 4108361,
     "sourceId": 7122490,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4121860,
     "sourceId": 7141413,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4127856,
     "sourceId": 7149637,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4128229,
     "sourceId": 7150171,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4128617,
     "sourceId": 7150740,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 150248402,
     "sourceType": "kernelVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 49.67115,
   "end_time": "2023-12-09T04:22:11.108251",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-12-09T04:21:21.437101",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
